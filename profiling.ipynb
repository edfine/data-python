{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-benchmarks and timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def build_concat(strings):\n",
    "    result = ''\n",
    "    for s in strings:\n",
    "        result += s\n",
    "    return result\n",
    "\n",
    "def build_join(strings):\n",
    "    return ''.join(strings)\n",
    "\n",
    "def build_sio(strings):\n",
    "    sio = io.StringIO()\n",
    "    for s in strings:\n",
    "        sio.write(s)\n",
    "    return sio.getvalue()\n",
    "\n",
    "strings = [str(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_concat(strings) == build_join(strings) == build_sio(strings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in ('concat', 'join', 'sio'):\n",
    "    elapsed = timeit.timeit(\n",
    "        'build_%s(strings)' % fname, \n",
    "        globals=globals(),\n",
    "        number=10_000)\n",
    "    print(fname, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook (and IPython) provide a nice helper\n",
    "\n",
    "We can use `%timeit` (or usually just `timeit`) to run a version of `timeit` in IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "build_concat(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit build_join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit build_sio(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of our microbenchmark\n",
    "\n",
    "- `''.join()` is the fastest, around 10x faster than concatenating strings\n",
    "- You should use `''.join` when you need to build a big string from a list of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling Python Code\n",
    "\n",
    "You can profile an entire script by running it via `python -m cProfile` to get summary information about the whole thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data/profiling/profiletest.py\n",
    "import re\n",
    "\n",
    "text = '''The quick brown fox jumps over the lazy dog'''\n",
    "for x in range(10_000):\n",
    "    re.search('fox', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python -m cProfile data/profiling/profiletest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cProfile --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m cProfile -s time data/profiling/profiletest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file data/profiling/profiletest.py\n",
    "import re\n",
    "\n",
    "text = '''The quick brown fox jumps over the lazy dog'''\n",
    "my_regex = re.compile('fox')\n",
    "for x in range(10_000):\n",
    "    my_regex.search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m cProfile -s time data/profiling/profiletest.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -p data/profiling/profiletest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cProfile -s time -o profile-stats data/profiling/profiletest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct profiling\n",
    "\n",
    "We can also profile just a few Python statements or a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cProfile.run('re.compile(\"foo|bar\")', sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the statistics to a file for analysis later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('re.compile(\"foo|bar\")', 're-stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analysis, we use the `pstats` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats('profile-stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.strip_dirs()\n",
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.sort_stats('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter / IPython also has a magic function to help us here, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun for x in range(10000): re.compile('foo|bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun \n",
    "for x in range(10000): \n",
    "    re.compile('foo|bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cProfile.Profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.enable()\n",
    "for x in range(10000):\n",
    "    re.compile('re|foo')\n",
    "    lst0 = range(100)\n",
    "    lst1 = list(range(100))\n",
    "p.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with p:\n",
    "    re.compile('re|foo')\n",
    "    lst0 = range(100)\n",
    "    lst1 = list(range(100))\n",
    "p.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Profilers are already context managers in Python 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def profiler(p):\n",
    "    p.enable()\n",
    "    try:\n",
    "        yield p\n",
    "    finally:\n",
    "        p.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profiler(p):\n",
    "    for x in range(10000):\n",
    "        re.compile('re|foo')\n",
    "        lst0 = range(100)\n",
    "        lst1 = list(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumenting high-performance code\n",
    "\n",
    "There are times when we want to profile, but we don't want to incur the performance penalty. For instance, we might want to see the profile of a running production system, without impacting its performance in a major way.\n",
    "\n",
    "For that, we can profile a _sample_ of the calls to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import functools\n",
    "\n",
    "def instrument(profiler, probability=0.10):\n",
    "    '''Profile some of the calls to the decorated function.\n",
    "    \n",
    "    The default probability of profiling a call is 10%.\n",
    "    '''\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            if random.random() < probability:\n",
    "                with profiler:  #if py38+\n",
    "                    return func(*args, **kwargs)\n",
    "#                 try:\n",
    "#                     profiler.enable()\n",
    "#                     return func(*args, **kwargs)\n",
    "#                 finally:\n",
    "#                     profiler.disable()\n",
    "            else:\n",
    "                return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "prof = cProfile.Profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@instrument(prof, 0.2)\n",
    "def build_join(strings):\n",
    "    return ''.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10_000): \n",
    "    build_join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def profiling(profiler, probability=0.10):\n",
    "    if random.random() < probability:\n",
    "        with profiler:\n",
    "            yield profiler\n",
    "#         try:\n",
    "#             profiler.enable()\n",
    "#             yield profiler\n",
    "#         finally:\n",
    "#             profiler.disable()\n",
    "    else:\n",
    "        yield None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit random.random() < 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = cProfile.Profile()\n",
    "prof1 = cProfile.Profile()\n",
    "\n",
    "num_profiles = 0\n",
    "for x in range(10_000): \n",
    "    with profiling(prof, 0.02) as as_value:\n",
    "        with profiling(prof1, 0.5) as as_value1:\n",
    "            # If profiling, as_value == prof\n",
    "            # If NOT profiling, as_value == None\n",
    "            if as_value:\n",
    "                num_profiles += 1\n",
    "            ''.join(strings)\n",
    "\n",
    "prof.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof1.print_stats(sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab\n",
    "\n",
    "Open the [profiling lab][profiling_lab]\n",
    "\n",
    "[profiling_lab]: ./profiling-lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_discovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:39:48) \n[Clang 11.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5843dadf34720d1d49bd40b40c179895302ad51d2a706663a7036f5f983c84b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
